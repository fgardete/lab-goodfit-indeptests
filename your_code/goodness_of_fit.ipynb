{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjd8WpUaVXTw"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkwpOykpWFyP"
   },
   "outputs": [],
   "source": [
    "#compute Expected number of observations under H0, and Observed in reality \n",
    "O = np.array([120,80,100])\n",
    "E = np.array([120,90,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8QrqKGKG9_z"
   },
   "outputs": [],
   "source": [
    "#significace level of 5%\n",
    "sl = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_asxXWjxWO2O",
    "outputId": "cd02c405-d4ee-472a-cd36-25752009fa2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.11111111 1.11111111]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2222222222222223"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute statistic for chi2\n",
    "print(np.square(O-E)/E)\n",
    "stat = (np.square(O-E)/E).sum()\n",
    "stat\n",
    "\n",
    "# here I'm just replicating the steps we did on the example\n",
    "\n",
    "# And now we want to see if this value is very unlikly or not by computing the p_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W808uoKjW5JP",
    "outputId": "e394dd6e-a3ef-4639-cecd-4b36f77d28dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3291929878079054"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check chi2-value for given significance (or confidence) level and the appriopriate number of degrees of freedom (number of categories -1)\n",
    "\n",
    "st.chi2.sf(abs(stat),df=3-1)\n",
    "\n",
    "# Here the degrees of freedom is a little bit diffrent from the t-distribution.\n",
    "# The degrees of freedom are the number of categories (in this case number of items in the vending machine) minus 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1-cGin1XqL3",
    "outputId": "2f7cab45-84bf-416c-a400-6d971074d758"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since our p value is relatively higher than (<5%), we do not reject our null\n",
    "\n",
    "#should we reject?\n",
    "\n",
    "0.3291929878079054 < 0.05\n",
    "\n",
    "# so our vending machine would show enough evidence to say that it follows the UNILIVER distribution.\n",
    "# so it is resonable to assume the Uniliver distribution (40%,30%,30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTiKmmNUWgRA",
    "outputId": "c734db9b-ecf4-40ee-a051-e004aab8902a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=2.2222222222222223, pvalue=0.3291929878079054)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can also do all of this in a line\n",
    "## total number of bottles = 300\n",
    "\n",
    "f_exp = np.array([0.4, 0.3,0.3]) * 300\n",
    "\n",
    "st.chisquare([120,80,100], f_exp=[120,90,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEG6wzmjwDhB"
   },
   "outputs": [],
   "source": [
    "#do it yourself\n",
    "#suppose we observed instead 180 cokes, 210 pepsis and 210 waters.\n",
    "# Unilever sltill claim:\n",
    "# 40% cokes, 30% pepsi, 30% water \n",
    "\n",
    "#Do we still not-reject at 1% significance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAcWXIqaWIfv"
   },
   "outputs": [],
   "source": [
    "O = [180,210,210]\n",
    "E = [0.4*600,0.3*600,0.3*600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCwdWOvMwVER",
    "outputId": "3d47e5f9-08a0-4d04-9dca-803c3af44e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=25.0, pvalue=3.7266531720786718e-06)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7266531720786718e-06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answer\n",
    "print(st.chisquare([180,210,210], f_exp=[0.4*600,0.3*600,0.3*600]))\n",
    "\n",
    "O = np.array([180,210,210])\n",
    "E = np.array([240,180,180])\n",
    "\n",
    "\n",
    "st.chi2.sf((np.square(O-E)/E).sum(),df=3-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ccBRFr-aoQ2"
   },
   "outputs": [],
   "source": [
    "# this is a so rare deviation (p-value very very low, and smaller that the error we are acepting to commit) that I prefer \n",
    "# to reject my null hypotesis, that to belive that I hit the jackpot.\n",
    "\n",
    "#SLIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDmZxRoGaoTa"
   },
   "outputs": [],
   "source": [
    "# Computing expected number of observations for distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jb1lmdfzaoWO",
    "outputId": "a8fb8045-5b25-4880-bdd3-8210a72910d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3       , 0.21      , 0.147     , 0.1029    , 0.07203   ,\n",
       "       0.050421  , 0.0352947 , 0.02470629, 0.0172944 , 0.01210608])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for class\n",
    "from scipy.stats import geom\n",
    "p=0.3\n",
    "geometric_dist = geom(p)\n",
    "\n",
    "geometric_pmfs = np.array([geometric_dist.pmf(i) for i in range(1,11)]) #. up until 10\n",
    "geometric_pmfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsrJsnbvhTWZ",
    "outputId": "b9bc2441-642c-4d09-91b6-2226b3b384b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3        0.21       0.147      0.1029     0.07203    0.050421\n",
      " 0.0352947  0.02470629 0.0172944  0.01210608 0.02824752]\n",
      "[60.         42.         29.4        20.58       14.406      10.0842\n",
      "  7.05894     4.941258    3.4588806   2.42121642  5.64950498]\n"
     ]
    }
   ],
   "source": [
    "#solving the problem\n",
    "# I don't have the last value so I need to apend the last value wich is the cahnce of getting greater than ten\n",
    "with_tail = np.append(geometric_pmfs,1-geometric_pmfs.sum()) #or np.append(geometric_pmfs, geometric_dist.sf(10)) #or np.append(geometric_pmfs, 1-geometric_dist.cdf(10))\n",
    "print(with_tail)\n",
    "E = with_tail*200\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6CNNtH1hEDa",
    "outputId": "a160f424-41bd-4774-8848-25308fb9389e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=14.349488995700755, pvalue=0.15763881414387987)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's comput at a 5% significance level\n",
    "\n",
    "st.chisquare([55,40,38,28,10,6,9,1,2,4,7],f_exp=E)\n",
    "\n",
    "# if we were doing by hand the number of dgrees of freedom would be 10 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWVbwk5JfxIO",
    "outputId": "c49722ce-7e38-47cb-8f48-839f05b3bde7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_dist.pmf(0)\n",
    "#we do not reject out hypothesis: this does seem to come from a geometric 0.3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mu_QTqxFtjRF"
   },
   "outputs": [],
   "source": [
    "## Now I want to show you that this is not an easy fit to do\n",
    "\n",
    "#do it yourself\n",
    "#does the distribution conform to a geometric 0.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LM05sGGjx-pk",
    "outputId": "ca62591b-68b5-46fc-d536-7554771d28e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=42.86458790302275, pvalue=5.258035233431057e-06)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometric_pmfs = np.array([geom(0.20).pmf(i) for i in range(1,11)])\n",
    "E = np.append(geometric_pmfs,1-geometric_pmfs.sum())*200\n",
    "st.chisquare([55,40,38,28,10,6,9,1,2,4,7],f_exp=E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkhJ8vGiU4xV"
   },
   "outputs": [],
   "source": [
    "# In this example we were given what was the expected parameter for the geometric distribution.\n",
    "# But we can gess this parameter by knowing that the mean is 1/p: https://en.wikipedia.org/wiki/Geometric_distribution \n",
    "\n",
    "# So if we belive this distibution came from a geometric distribution the mean should be a good approximation of 1/p.\n",
    "\n",
    "# THe best way for me to do this, is to comput the mean of our observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqwz7K84J9Dz"
   },
   "outputs": [],
   "source": [
    "#mean = 1/p   <= > p = 1/mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdL5kvtzjEtJ",
    "outputId": "24731e67-d778-4799-dfee-99244da776d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30627871362940273"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 1/(np.array([55*1,40*2,38*3,28*4,10*5,6*6,9*7,1*8,2*9,4*10,7*11]).sum()/200) # I will comite a mistke because I don't have really good way to comput larger than 10 so I'm considering 11\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "bmcMnWFVKB79",
    "outputId": "ebbc0426-b065-449f-b6bd-4662865b0d33"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d8a395d23c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#unknown parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Estimated p = 0.306\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgeometric_pmfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.306\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeometric_pmfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgeometric_pmfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_exp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d8a395d23c66>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#unknown parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Estimated p = 0.306\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgeometric_pmfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.306\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeometric_pmfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgeometric_pmfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m38\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_exp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geom' is not defined"
     ]
    }
   ],
   "source": [
    "#unknown parameter\n",
    "#Estimated p = 0.306\n",
    "geometric_pmfs = np.array([geom(0.306).pmf(i) for i in range(1,11)])\n",
    "expected = np.append(geometric_pmfs,1-geometric_pmfs.sum())*200\n",
    "st.chisquare([55,40,38,28,10,6,9,1,2,4,7],f_exp=expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxMVgveckpU-"
   },
   "outputs": [],
   "source": [
    "# So for all the distributions we have seen the parameter can be extrated from the mean and the mean can be extracted from the our observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ma7AaUTXkpX6"
   },
   "outputs": [],
   "source": [
    "# assuming a poisson now\n",
    "# mean = lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LZJHT6pkvE1",
    "outputId": "7c13bc4a-fa74-40aa-a856-bba608d92d32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.265"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([55*1,40*2,38*3,28*4,10*5,6*6,9*7,1*8,2*9,4*10,7*11]).sum()/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c_ATfoAk2Mx"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvqWRwPmkpa6",
    "outputId": "15e61bcc-9f27-4409-9c2d-cdc937df139f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=101.81468891266596, pvalue=2.3600248735756413e-17)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson_pmfs = np.array([poisson(3.265).pmf(i) for i in range(1,11)])\n",
    "expected = np.append(poisson_pmfs,1-poisson_pmfs.sum())*200\n",
    "st.chisquare([55,40,38,28,10,6,9,1,2,4,7],f_exp=expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUL8lLckJ9Gq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ivDlmAY1tjTy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QvCvHzretjXa",
    "outputId": "bf7e2d33-82cd-465d-c0fb-4c77ab041e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.8113499370887,\n",
       " 1.5065700686908928e-06,\n",
       " 2,\n",
       " array([[233.50877193,  96.49122807],\n",
       "        [ 58.73099415,  24.26900585],\n",
       "        [ 70.76023392,  29.23976608]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contingency tables and independence of effects\n",
    "import scipy.stats as st\n",
    "\n",
    "#we just need the observed values \n",
    "\n",
    "cars_table=[[256,74],\n",
    "            [41,42],\n",
    "            [66,34]]\n",
    "\n",
    "st.chi2_contingency(np.array(cars_table))\n",
    "#statistic, p-value, degrees of freedom, expected probs if H0 holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AX--aPwudw8"
   },
   "outputs": [],
   "source": [
    "#seems like our car manufacturers are actually quite differentiated.\n",
    "#good for them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xeIFqx_cuOYR"
   },
   "outputs": [],
   "source": [
    "#our conclusion is that the brands influence the preception \n",
    "\n",
    "\n",
    "### tuple from chi2_contingency:\n",
    "### 1st element: statistic\n",
    "### 2nd element: p_value\n",
    "### 3rd element: degrees of freedom = (number of columns - 1)*(number of rows - 1)\n",
    "### 4th element: the expected values if H0 stands true. If the car type is independent of the perception \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# we reject the null hypotesis \n",
    "\n",
    "## seems that our car manufacturers are actually quite diferenciated \n",
    "## seems that brands influence preception and perception influeces brands "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "goodness_of_fit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
